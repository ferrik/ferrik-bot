"""
üîç –Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –ø–æ—à—É–∫ –ø–æ –º–µ–Ω—é –∑ NLP
"""
import re
from typing import List, Dict, Set
from difflib import SequenceMatcher
import logging

logger = logging.getLogger(__name__)


class MenuSearch:
    """–Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –ø–æ—à—É–∫ –ø–æ –º–µ–Ω—é"""
    
    # –°–ª–æ–≤–Ω–∏–∫ —Å–∏–Ω–æ–Ω—ñ–º—ñ–≤ —Ç–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∏—Ö –Ω–∞–∑–≤
    SYNONYMS = {
        '–ø—ñ—Ü–∞': ['pizza', '–ø—ñ—Ü–∞', '–ø—ñ—Ü—Ü–∞'],
        '–±—É—Ä–≥–µ—Ä': ['burger', '–≥–∞–º–±—É—Ä–≥–µ—Ä', '—á—ñ–∑–±—É—Ä–≥–µ—Ä'],
        '—Å–∞–ª–∞—Ç': ['salad', '–æ–≤–æ—á—ñ', '–∑–µ–ª–µ–Ω—å'],
        '—Å—É–ø': ['soup', '—é—à–∫–∞', '–±—É–ª—å–π–æ–Ω'],
        '–¥–µ—Å–µ—Ä—Ç': ['dessert', '—Å–æ–ª–æ–¥–∫–µ', '—Ç—ñ—Å—Ç–µ—á–∫–æ', '—Ç–æ—Ä—Ç'],
        '–Ω–∞–ø—ñ–π': ['drink', 'beverage', '—Å—ñ–∫', '–∫–æ–º–ø–æ—Ç'],
        '–∫–∞–≤–∞': ['coffee', '–µ—Å–ø—Ä–µ—Å–æ', '–∫–∞–ø—É—á—ñ–Ω–æ', '–ª–∞—Ç—Ç–µ'],
        '–º\'—è—Å–æ': ['meat', '—è–ª–æ–≤–∏—á–∏–Ω–∞', '—Å–≤–∏–Ω–∏–Ω–∞', '–∫—É—Ä–∫–∞', '–∫—É—Ä—è—á–∏–π'],
        '—Ä–∏–±–∞': ['fish', '—Ñ–æ—Ä–µ–ª—å', '–ª–æ—Å–æ—Å—å', '—Ç—É–Ω–µ—Ü—å'],
        '–≤–µ–≥–µ—Ç–∞—Ä—ñ–∞–Ω—Å—å–∫–∏–π': ['vegetarian', 'vegan', '–±–µ–∑ –º\'—è—Å–∞', '–æ–≤–æ—á–µ–≤–∏–π'],
        '–≥–æ—Å—Ç—Ä–∏–π': ['spicy', 'hot', '–ø–µ—Ä—á–µ–Ω–∏–π'],
        '—Å–∏—Ä': ['cheese', '—á—ñ–∑', '—Å–∏—Ä–Ω–∏–π'],
        '—Ç–æ–º–∞—Ç': ['tomato', '–ø–æ–º—ñ–¥–æ—Ä', '—Ç–æ–º–∞—Ç–Ω–∏–π'],
        '–≥—Ä–∏–±–∏': ['mushroom', '–ø–µ—á–µ—Ä–∏—Ü—ñ', '–≥—Ä–∏–±–Ω–∏–π']
    }
    
    # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ (—ñ–≥–Ω–æ—Ä—É—é—Ç—å—Å—è –ø—Ä–∏ –ø–æ—à—É–∫—É)
    STOP_WORDS = {
        '–∑', '—ñ–∑', '–Ω–∞', '–≤', '—É', '—Ç–∞', '—ñ', '–∞–±–æ', '–±–µ–∑', '–ø—ñ–¥',
        'the', 'with', 'and', 'or', 'in', 'on'
    }
    
    # –ö–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –¥–ª—è —Ñ—ñ–ª—å—Ç—Ä—ñ–≤
    FILTER_KEYWORDS = {
        'vegetarian': ['–≤–µ–≥–µ—Ç–∞—Ä—ñ–∞–Ω—Å—å–∫–∏–π', '–±–µ–∑ –º\'—è—Å–∞', '–æ–≤–æ—á–µ–≤–∏–π', 'vegetarian', 'vegan'],
        'spicy': ['–≥–æ—Å—Ç—Ä–∏–π', '–ø–µ–∫—É—á–∏–π', 'spicy', 'hot'],
        'cheap': ['–¥–µ—à–µ–≤–∏–π', '–Ω–µ–¥–æ—Ä–æ–≥–∏–π', '–±—é–¥–∂–µ—Ç–Ω–∏–π', '–µ–∫–æ–Ω–æ–º'],
        'expensive': ['–¥–æ—Ä–æ–≥–∏–π', '–ø—Ä–µ–º—ñ—É–º', '–µ–ª—ñ—Ç–Ω–∏–π'],
        'fast': ['—à–≤–∏–¥–∫–∏–π', '—à–≤–∏–¥–∫–æ', 'fast', 'quick'],
        'new': ['–Ω–æ–≤–∏–π', '–Ω–æ–≤–µ', '–Ω–æ–≤–∏–Ω–∫–∞', 'new']
    }
    
    @staticmethod
    def normalize_text(text: str) -> str:
        """–ù–æ—Ä–º–∞–ª—ñ–∑—É—î —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ—à—É–∫—É"""
        # –ù–∏–∂–Ω—ñ–π —Ä–µ–≥—ñ—Å—Ç—Ä
        text = text.lower().strip()
        
        # –í–∏–¥–∞–ª–µ–Ω–Ω—è –∑–∞–π–≤–∏—Ö –ø—Ä–æ–±—ñ–ª—ñ–≤
        text = re.sub(r'\s+', ' ', text)
        
        # –í–∏–¥–∞–ª–µ–Ω–Ω—è —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ñ–≤ (–∑–∞–ª–∏—à–∞—î–º–æ –±—É–∫–≤–∏, —Ü–∏—Ñ—Ä–∏, –ø—Ä–æ–±—ñ–ª–∏)
        text = re.sub(r'[^\w\s\'-]', '', text, flags=re.UNICODE)
        
        return text
    
    @staticmethod
    def extract_keywords(query: str) -> Set[str]:
        """–í–∏—Ç—è–≥—É—î –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ –∑ –∑–∞–ø–∏—Ç—É"""
        normalized = MenuSearch.normalize_text(query)
        words = normalized.split()
        
        # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        keywords = {word for word in words if word not in MenuSearch.STOP_WORDS}
        
        # –î–æ–¥–∞—î–º–æ —Å–∏–Ω–æ–Ω—ñ–º–∏
        expanded_keywords = set(keywords)
        for keyword in keywords:
            for main_word, synonyms in MenuSearch.SYNONYMS.items():
                if keyword in synonyms:
                    expanded_keywords.add(main_word)
                    expanded_keywords.update(synonyms)
        
        return expanded_keywords
    
    @staticmethod
    def extract_filters(query: str) -> Dict[str, bool]:
        """–í–∏—Ç—è–≥—É—î —Ñ—ñ–ª—å—Ç—Ä–∏ –∑ –∑–∞–ø–∏—Ç—É"""
        normalized = MenuSearch.normalize_text(query)
        filters = {}
        
        for filter_name, keywords in MenuSearch.FILTER_KEYWORDS.items():
            for keyword in keywords:
                if keyword in normalized:
                    filters[filter_name] = True
                    break
        
        return filters
    
    @staticmethod
    def calculate_relevance(item: Dict, keywords: Set[str], filters: Dict) -> float:
        """
        –†–æ–∑—Ä–∞—Ö–æ–≤—É—î —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å —Ç–æ–≤–∞—Ä—É –¥–æ –ø–æ—à—É–∫–æ–≤–æ–≥–æ –∑–∞–ø–∏—Ç—É
        
        Returns:
            float: Score –≤—ñ–¥ 0 –¥–æ 100
        """
        score = 0.0
        
        # –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ–∫—Å—Ç—É —Ç–æ–≤–∞—Ä—É
        name = MenuSearch.normalize_text(item.get('name', item.get('–°—Ç—Ä–∞–≤–∏', '')))
        description = MenuSearch.normalize_text(item.get('description', item.get('–û–ø–∏—Å', '')))
        category = MenuSearch.normalize_text(item.get('category', item.get('–ö–∞—Ç–µ–≥–æ—Ä—ñ—è', '')))
        allergens = MenuSearch.normalize_text(item.get('allergens', item.get('–ê–ª–ª–µ—Ä–≥–µ–Ω–∏', '')))
        
        full_text = f"{name} {description} {category}"
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–∂–Ω–æ–≥–æ –∫–ª—é—á–æ–≤–æ–≥–æ —Å–ª–æ–≤–∞
        for keyword in keywords:
            # –¢–æ—á–Ω–∏–π –∑–±—ñ–≥ –≤ –Ω–∞–∑–≤—ñ (–Ω–∞–π–≤–∏—â–∏–π –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç)
            if keyword in name:
                score += 30.0
            
            # –ó–±—ñ–≥ –≤ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó
            elif keyword in category:
                score += 20.0
            
            # –ó–±—ñ–≥ –≤ –æ–ø–∏—Å—ñ
            elif keyword in description:
                score += 15.0
            
            # –ß–∞—Å—Ç–∫–æ–≤–µ —Å–ø—ñ–≤–ø–∞–¥–∞–Ω–Ω—è (fuzzy match)
            else:
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ —Å—Ö–æ–∂—ñ—Å—Ç—å –∑ –Ω–∞–∑–≤–æ—é
                ratio = SequenceMatcher(None, keyword, name).ratio()
                if ratio > 0.6:
                    score += 10.0 * ratio
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Ñ—ñ–ª—å—Ç—Ä—ñ–≤
        if filters:
            filter_match_count = 0
            
            # –í–µ–≥–µ—Ç–∞—Ä—ñ–∞–Ω—Å—å–∫–µ
            if filters.get('vegetarian'):
                if any(word in full_text for word in ['–≤–µ–≥–µ—Ç–∞—Ä—ñ–∞–Ω—Å—å–∫–∏–π', '–æ–≤–æ—á–µ–≤–∏–π', '—Å–∞–ª–∞—Ç']):
                    score += 10.0
                    filter_match_count += 1
                elif any(word in full_text for word in ['–º\'—è—Å–æ', '–∫—É—Ä–∫–∞', '—Å–≤–∏–Ω–∏–Ω–∞']):
                    score -= 20.0  # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å
            
            # –ì–æ—Å—Ç—Ä–µ
            if filters.get('spicy'):
                if any(word in full_text for word in ['–≥–æ—Å—Ç—Ä–∏–π', '–ø–µ—Ä–µ—Ü—å', '—á—ñ–ª—ñ']):
                    score += 10.0
                    filter_match_count += 1
            
            # –®–≤–∏–¥–∫–µ –ø—Ä–∏–≥–æ—Ç—É–≤–∞–Ω–Ω—è
            if filters.get('fast'):
                cook_time = int(item.get('cook_time', item.get('–ß–∞—Å_–ø—Ä–∏–≥–æ—Ç—É–≤–∞–Ω–Ω—è', 30)))
                if cook_time <= 20:
                    score += 10.0
                    filter_match_count += 1
            
            # –¶—ñ–Ω–∞
            price = float(item.get('price', item.get('–¶—ñ–Ω–∞', 0)))
            if filters.get('cheap') and price <= 150:
                score += 10.0
                filter_match_count += 1
            elif filters.get('expensive') and price >= 300:
                score += 10.0
                filter_match_count += 1
        
        # –ë–æ–Ω—É—Å –∑–∞ —Ä–µ–π—Ç–∏–Ω–≥
        rating = float(item.get('rating', item.get('–†–µ–π—Ç–∏–Ω–≥', 0)))
        if rating >= 4.5:
            score += 5.0
        
        return min(100.0, score)
    
    @staticmethod
    def search(query: str, items: List[Dict], limit: int = 10) -> List[Dict]:
        """
        –í–∏–∫–æ–Ω—É—î —ñ–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –ø–æ—à—É–∫
        
        Args:
            query: –ü–æ—à—É–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç
            items: –°–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä—ñ–≤
            limit: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–±—ñ–ª—å—à —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∏—Ö —Ç–æ–≤–∞—Ä—ñ–≤
        """
        if not query or not items:
            return []
        
        # –í–∏—Ç—è–≥—É—î–º–æ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞ —Ç–∞ —Ñ—ñ–ª—å—Ç—Ä–∏
        keywords = MenuSearch.extract_keywords(query)
        filters = MenuSearch.extract_filters(query)
        
        logger.info(f"Search query: {query}")
        logger.info(f"Keywords: {keywords}")
        logger.info(f"Filters: {filters}")
        
        # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—å –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä—É
        scored_items = []
        for item in items:
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ –∞–∫—Ç–∏–≤–Ω–∏–π —Ç–æ–≤–∞—Ä
            is_active = item.get('active', item.get('–ê–∫—Ç–∏–≤–Ω–∏–π', True))
            if not is_active:
                continue
            
            score = MenuSearch.calculate_relevance(item, keywords, filters)
            
            if score > 0:
                scored_items.append({
                    'item': item,
                    'score': score
                })
        
        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ñ—Å—Ç—é
        scored_items.sort(key=lambda x: x['score'], reverse=True)
        
        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ç–æ–ø N
        results = [si['item'] for si in scored_items[:limit]]
        
        logger.info(f"Found {len(results)} results")
        
        return results
    
    @staticmethod
    def format_search_results(results: List[Dict], query: str) -> str:
        """–§–æ—Ä–º–∞—Ç—É—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É"""
        if not results:
            return (
                f"üîç –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É: \"{query}\"\n\n"
                f"üòî –ù—ñ—á–æ–≥–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ.\n\n"
                f"üí° –°–ø—Ä–æ–±—É–π:\n"
                f"‚Ä¢ –Ü–Ω—à—ñ –∫–ª—é—á–æ–≤—ñ —Å–ª–æ–≤–∞\n"
                f"‚Ä¢ –ü–µ—Ä–µ–≥–ª—è–Ω—É—Ç–∏ –≤—Å–µ –º–µ–Ω—é: /menu\n"
                f"‚Ä¢ –ü—ñ–¥—ñ–±—Ä–∞—Ç–∏ —Å—Ç—Ä–∞–≤—É –∑–∞ –Ω–∞—Å—Ç—Ä–æ—î–º: /recommend"
            )
        
        result_text = f"üîç **–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ—à—É–∫—É:** \"{query}\"\n\n"
        result_text += f"–ó–Ω–∞–π–¥–µ–Ω–æ: **{len(results)}** –ø–æ–∑–∏—Ü—ñ–π\n\n"
        
        from menu_formatter import MenuFormatter
        
        for i, item in enumerate(results[:5], 1):  # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 5
            result_text += f"**{i}.** "
            result_text += MenuFormatter.format_item_card(item)
            result_text += "\n\n" + "-" * 40 + "\n\n"
        
        if len(results) > 5:
            result_text += f"_...—Ç–∞ —â–µ {len(results) - 5} –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤_\n"
        
        return result_text
    
    @staticmethod
    def create_search_keyboard(results: List[Dict]) -> Dict:
        """–°—Ç–≤–æ—Ä—é—î –∫–ª–∞–≤—ñ–∞—Ç—É—Ä—É –∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ—à—É–∫—É"""
        keyboard = {'inline_keyboard': []}
        
        for item in results[:5]:
            item_id = item.get('id', item.get('ID'))
            name = item.get('name', item.get('–°—Ç—Ä–∞–≤–∏', ''))[:30]
            
            keyboard['inline_keyboard'].append([
                {'text': f"üëÅÔ∏è {name}", 'callback_data': f"item_{item_id}"},
                {'text': '‚ûï', 'callback_data': f"add_{item_id}"}
            ])
        
        keyboard['inline_keyboard'].append([
            {'text': 'üîÑ –ù–æ–≤–∏–π –ø–æ—à—É–∫', 'callback_data': 'search_menu'},
            {'text': 'üìã –í—Å–µ –º–µ–Ω—é', 'callback_data': 'menu'}
        ])
        
        return keyboard
    
    @staticmethod
    def get_search_suggestions() -> List[str]:
        """–ü–æ–≤–µ—Ä—Ç–∞—î –ø–æ–ø—É–ª—è—Ä–Ω—ñ –ø–æ—à—É–∫–æ–≤—ñ –∑–∞–ø–∏—Ç–∏"""
        return [
            "–ø—ñ—Ü–∞ –∑ –≥—Ä–∏–±–∞–º–∏",
            "—â–æ—Å—å –≤–µ–≥–µ—Ç–∞—Ä—ñ–∞–Ω—Å—å–∫–µ",
            "–≥–æ—Å—Ç—Ä–∏–π —Å—É–ø",
            "–¥–µ—Å–µ—Ä—Ç –±–µ–∑ –≥–ª—é—Ç–µ–Ω—É",
            "—à–≤–∏–¥–∫–∏–π –ø–µ—Ä–µ–∫—É—Å",
            "–º'—è—Å–Ω–∞ —Å—Ç—Ä–∞–≤–∞",
            "–ª–µ–≥–∫–∏–π —Å–∞–ª–∞—Ç",
            "–∫–∞–≤—É –∑ –¥–µ—Å–µ—Ä—Ç–æ–º"
        ]


# ============================================================================
# –î–æ–ø–æ–º—ñ–∂–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó
# ============================================================================

def handle_search(user_id: int, query: str, telegram_api, sheets_api):
    """–û–±—Ä–æ–±–ª—è—î –ø–æ—à—É–∫–æ–≤–∏–π –∑–∞–ø–∏—Ç"""
    # –û—Ç—Ä–∏–º—É—î–º–æ –º–µ–Ω—é
    menu_items = sheets_api.get_menu()
    
    if not menu_items:
        telegram_api.send_message(
            user_id,
            "üòî –ù–∞ –∂–∞–ª—å, –∑–∞—Ä–∞–∑ –º–µ–Ω—é –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–µ. –°–ø—Ä–æ–±—É–π –ø—ñ–∑–Ω—ñ—à–µ!"
        )
        return
    
    # –í–∏–∫–æ–Ω—É—î–º–æ –ø–æ—à—É–∫
    results = MenuSearch.search(query, menu_items, limit=10)
    
    # –§–æ—Ä–º–∞—Ç—É—î–º–æ —Ç–∞ –≤—ñ–¥–ø—Ä–∞–≤–ª—è—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    result_text = MenuSearch.format_search_results(results, query)
    result_keyboard = MenuSearch.create_search_keyboard(results)
    
    telegram_api.send_message(user_id, result_text, reply_markup=result_keyboard)


# ============================================================================
# –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è
# ============================================================================
if __name__ == "__main__":
    # –¢–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ
    test_items = [
        {
            'id': 1,
            'name': '–ü—ñ—Ü–∞ "–ú–∞—Ä–≥–∞—Ä–∏—Ç–∞"',
            'category': '–ü—ñ—Ü–∞',
            'description': '–ö–ª–∞—Å–∏—á–Ω–∞ —ñ—Ç–∞–ª—ñ–π—Å—å–∫–∞ –ø—ñ—Ü–∞ –∑ –º–æ—Ü–∞—Ä–µ–ª–æ—é —Ç–∞ —Ç–æ–º–∞—Ç–∞–º–∏',
            'price': 180,
            'rating': 4.8,
            'cook_time': 20
        },
        {
            'id': 2,
            'name': '–°–∞–ª–∞—Ç "–¶–µ–∑–∞—Ä"',
            'category': '–°–∞–ª–∞—Ç–∏',
            'description': '–°–≤—ñ–∂–∏–π —Å–∞–ª–∞—Ç –∑ –∫—É—Ä–∫–æ—é, –ø–∞—Ä–º–µ–∑–∞–Ω–æ–º —Ç–∞ —Å–æ—É—Å–æ–º',
            'price': 150,
            'rating': 4.6,
            'cook_time': 10
        },
        {
            'id': 3,
            'name': '–û–≤–æ—á–µ–≤–∏–π —Å—É–ø',
            'category': '–°—É–ø–∏',
            'description': '–õ–µ–≥–∫–∏–π –≤–µ–≥–µ—Ç–∞—Ä—ñ–∞–Ω—Å—å–∫–∏–π —Å—É–ø –∑ —Å–µ–∑–æ–Ω–Ω–∏—Ö –æ–≤–æ—á—ñ–≤',
            'price': 95,
            'rating': 4.5,
            'cook_time': 15
        },
        {
            'id': 4,
            'name': '–ë—É—Ä–≥–µ—Ä –∑ –≥—Ä–∏–±–∞–º–∏',
            'category': '–ë—É—Ä–≥–µ—Ä–∏',
            'description': '–°–æ–∫–æ–≤–∏—Ç–∏–π –±—É—Ä–≥–µ—Ä –∑ –ø–µ—á–µ—Ä–∏—Ü—è–º–∏ —Ç–∞ —Å–∏—Ä–æ–º',
            'price': 165,
            'rating': 4.7,
            'cook_time': 18
        }
    ]
    
    # –¢–µ—Å—Ç–æ–≤—ñ –∑–∞–ø–∏—Ç–∏
    test_queries = [
        "–ø—ñ—Ü–∞ –∑ —Å–∏—Ä–æ–º",
        "—â–æ—Å—å –≤–µ–≥–µ—Ç–∞—Ä—ñ–∞–Ω—Å—å–∫–µ",
        "—à–≤–∏–¥–∫–∏–π –ø–µ—Ä–µ–∫—É—Å",
        "–±—É—Ä–≥–µ—Ä",
        "—Å–∞–ª–∞—Ç –±–µ–∑ –º'—è—Å–∞"
    ]
    
    print("=== –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è –ø–æ—à—É–∫—É ===\n")
    
    for query in test_queries:
        print(f"\n{'='*50}")
        print(f"–ó–∞–ø–∏—Ç: {query}")
        print('='*50)
        
        results = MenuSearch.search(query, test_items, limit=3)
        print(MenuSearch.format_search_results(results, query))
